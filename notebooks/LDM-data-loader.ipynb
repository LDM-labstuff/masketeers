{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98457078",
   "metadata": {},
   "source": [
    "1. Obtain cropped images from zarr file, max project them and save them back to the zarr file\n",
    "Only need to run this cell once! Once the cropped images are saved as max projections go directly to the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "59f479c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatments found in zarr file: ['8nMActD', 'DMSO', '1uMdoxo', 'CX5461', '5uMflavo', '800nMActD', '10uMmg132', '10uMwort']\n",
      "Image array for 8nMActD has 1763 images\n",
      "Image shape is: (15, 3, 128, 128)\n",
      "Image array for DMSO has 2044 images\n",
      "Image shape is: (15, 3, 128, 128)\n",
      "Image array for 1uMdoxo has 1062 images\n",
      "Image shape is: (15, 3, 128, 128)\n",
      "Image array for CX5461 has 2189 images\n",
      "Image shape is: (15, 3, 128, 128)\n",
      "Image array for 5uMflavo has 1493 images\n",
      "Image shape is: (15, 3, 128, 128)\n",
      "Image array for 800nMActD has 1654 images\n",
      "Image shape is: (15, 3, 128, 128)\n",
      "Image array for 10uMmg132 has 1183 images\n",
      "Image shape is: (15, 3, 128, 128)\n",
      "Image array for 10uMwort has 1820 images\n",
      "Image shape is: (15, 3, 128, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images for 8nMActD: 100%|██████████| 1763/1763 [06:12<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created array for treatment '8nMActD' with shape (1763, 3, 128, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images for DMSO: 100%|██████████| 2044/2044 [07:40<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created array for treatment 'DMSO' with shape (2044, 3, 128, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images for 1uMdoxo: 100%|██████████| 1062/1062 [02:22<00:00,  7.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created array for treatment '1uMdoxo' with shape (1062, 3, 128, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images for CX5461: 100%|██████████| 2189/2189 [08:14<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created array for treatment 'CX5461' with shape (2189, 3, 128, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images for 5uMflavo: 100%|██████████| 1493/1493 [03:43<00:00,  6.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created array for treatment '5uMflavo' with shape (1493, 3, 128, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images for 800nMActD: 100%|██████████| 1654/1654 [05:49<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created array for treatment '800nMActD' with shape (1654, 3, 128, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images for 10uMmg132: 100%|██████████| 1183/1183 [02:42<00:00,  7.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created array for treatment '10uMmg132' with shape (1183, 3, 128, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images for 10uMwort: 100%|██████████| 1820/1820 [06:28<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created array for treatment '10uMwort' with shape (1820, 3, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "import zarr\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Load zarr file\n",
    "z= zarr.open(\"/mnt/efs/aimbl_2025/student_data/S-DD/LDM_treatments.zarr\", mode=\"r\")\n",
    "\n",
    "# Explore zarr to find treatments and masks\n",
    "def obtain_image_dataset_size(zarr_array):\n",
    "    # Identify treatmens in the zarr file\n",
    "    treatments = list(z.keys())\n",
    "    print(f\"Treatments found in zarr file: {treatments}\")\n",
    "    treatment_image_num = {}\n",
    "    for treatment in treatments:\n",
    "        image_num = z[treatment]['cimages_maskout'].shape[0]\n",
    "        treatment_image_num[treatment] = image_num\n",
    "        print(f\"Image array for {treatment} has {image_num} images\")\n",
    "        image_shape = z[treatment]['cimages_maskout'][0].shape\n",
    "        print(f\"Image shape is: {image_shape}\")\n",
    "    return treatments, treatment_image_num\n",
    "def max_project_images(treatments, z):\n",
    "    # Load images into the numpy array\n",
    "    for treatment in treatments:\n",
    "        num_images = treatment_image_num[treatment]\n",
    "        treatment_proj_array = np.zeros((num_images, 3, 128, 128), dtype=np.uint8)\n",
    "        for i in tqdm(range(num_images), desc=f\"Loading images for {treatment}\"):\n",
    "            image = z[treatment]['cimages_maskout'][i]\n",
    "            treatment_proj_array[i] = np.max(image, axis=0)\n",
    "            image = z[treatment]['cimages_maskout'][i]\n",
    "            treatment_proj_array[i] = np.max(image, axis=0)\n",
    "        print(f\"Created array for treatment '{treatment}' with shape {treatment_proj_array.shape}\")\n",
    "  \n",
    "        # Save the numpy array to the zarr file\n",
    "        zarr.create_array(store=\"/mnt/efs/aimbl_2025/student_data/S-DD/LDM_treatments.zarr\", name=f\"{treatment}/cimages_max\", data= treatment_proj_array, chunks=(1, 3, 128, 128))\n",
    "\n",
    "treatments, treatment_image_num = obtain_image_dataset_size(z)\n",
    "# for treatment in treatments:\n",
    "#     print(f\"Image number for treatment {treatment} is {treatment_image_num[treatment]}\")\n",
    "treatment_proj_array = max_project_images(treatments, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd89bba5",
   "metadata": {},
   "source": [
    "Load images from zarr to torch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "03b972aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the treatment group shape is (1183, 3, 128, 128)\n",
      "the treatment group shape is (1062, 3, 128, 128)\n",
      "the treatment group shape is (2044, 3, 128, 128)\n",
      "the treatment group shape is (1763, 3, 128, 128)\n",
      "the treatment group shape is (1493, 3, 128, 128)\n",
      "the treatment group shape is (1820, 3, 128, 128)\n",
      "the treatment group shape is (1654, 3, 128, 128)\n",
      "the treatment group shape is (2189, 3, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "import zarr\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "class ZarrImageDataset(Dataset):\n",
    "    def __init__(self, zarr_path, transform=None):\n",
    "        self.root = zarr.open(zarr_path, mode='r')\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.label_map = {name: idx for idx, name in enumerate(self.root.group_keys())}\n",
    "\n",
    "        # Load images and labels\n",
    "        # map treatments to integer labels\n",
    "        for treatment_name in self.root.group_keys():\n",
    "            treatment_group = self.root[treatment_name]['cimages_max']\n",
    "            print(f\"the treatment group shape is {treatment_group.shape}\")\n",
    "            for i in range(treatment_group.shape[0]):\n",
    "                img = treatment_group[i]\n",
    "                self.images.append(img)\n",
    "                self.labels.append(treatment_name)\n",
    "        self.labels = np.array(self.labels).reshape(-1, 1)\n",
    "        enc = OneHotEncoder(categories=[['8nMActD', 'DMSO', '1uMdoxo', 'CX5461', '5uMflavo', '800nMActD', '10uMmg132', '10uMwort']]).fit(self.labels)\n",
    "        self.labels = enc.transform(self.labels).toarray()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        print(f\"Image shape is: {img.shape}\")\n",
    "        # Convert to torch tensor\n",
    "        img_tensor = torch.tensor(img, dtype=torch.float32)\n",
    "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        if self.transform:\n",
    "            img_tensor = self.transform(img_tensor)\n",
    "\n",
    "        return img_tensor, label_tensor\n",
    "\n",
    "# Call the function to create the dataset\n",
    "zarr_path = '/mnt/efs/aimbl_2025/student_data/S-DD/LDM_treatments.zarr'\n",
    "dataset = ZarrImageDataset(zarr_path)\n",
    "# # Data loader\n",
    "# loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b1ba86f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape is: (3, 128, 128)\n",
      "Image 0 shape: torch.Size([3, 128, 128]), dtype: torch.float32\n",
      "Label 0: tensor([0, 0, 0, 0, 0, 0, 1, 0])\n",
      "Image shape is: (3, 128, 128)\n",
      "Image 1 shape: torch.Size([3, 128, 128]), dtype: torch.float32\n",
      "Label 1: tensor([0, 0, 0, 0, 0, 0, 1, 0])\n",
      "Image shape is: (3, 128, 128)\n",
      "Image 2 shape: torch.Size([3, 128, 128]), dtype: torch.float32\n",
      "Label 2: tensor([0, 0, 0, 0, 0, 0, 1, 0])\n",
      "Image shape is: (3, 128, 128)\n",
      "Image 3 shape: torch.Size([3, 128, 128]), dtype: torch.float32\n",
      "Label 3: tensor([0, 0, 0, 0, 0, 0, 1, 0])\n",
      "Image shape is: (3, 128, 128)\n",
      "Image 4 shape: torch.Size([3, 128, 128]), dtype: torch.float32\n",
      "Label 4: tensor([0, 0, 0, 0, 0, 0, 1, 0])\n",
      "Image shape is: (3, 128, 128)\n",
      "Image 5 shape: torch.Size([3, 128, 128]), dtype: torch.float32\n",
      "Label 5: tensor([0, 0, 0, 0, 0, 0, 1, 0])\n",
      "Image shape is: (3, 128, 128)\n",
      "Image 6 shape: torch.Size([3, 128, 128]), dtype: torch.float32\n",
      "Label 6: tensor([0, 0, 0, 0, 0, 0, 1, 0])\n",
      "Image shape is: (3, 128, 128)\n",
      "Image 7 shape: torch.Size([3, 128, 128]), dtype: torch.float32\n",
      "Label 7: tensor([0, 0, 0, 0, 0, 0, 1, 0])\n",
      "Image shape is: (3, 128, 128)\n",
      "Image 8 shape: torch.Size([3, 128, 128]), dtype: torch.float32\n",
      "Label 8: tensor([0, 0, 0, 0, 0, 0, 1, 0])\n",
      "Image shape is: (3, 128, 128)\n",
      "Image 9 shape: torch.Size([3, 128, 128]), dtype: torch.float32\n",
      "Label 9: tensor([0, 0, 0, 0, 0, 0, 1, 0])\n",
      "Image shape is: (3, 128, 128)\n",
      "Image 10 shape: torch.Size([3, 128, 128]), dtype: torch.float32\n",
      "Label 10: tensor([0, 0, 0, 0, 0, 0, 1, 0])\n",
      "Image shape is: (3, 128, 128)\n",
      "Image 11 shape: torch.Size([3, 128, 128]), dtype: torch.float32\n",
      "Label 11: tensor([0, 0, 0, 0, 0, 0, 1, 0])\n",
      "Image shape is: (3, 128, 128)\n",
      "Image 12 shape: torch.Size([3, 128, 128]), dtype: torch.float32\n",
      "Label 12: tensor([0, 0, 0, 0, 0, 0, 1, 0])\n",
      "Image shape is: (3, 128, 128)\n",
      "Image 13 shape: torch.Size([3, 128, 128]), dtype: torch.float32\n",
      "Label 13: tensor([0, 0, 0, 0, 0, 0, 1, 0])\n",
      "Image shape is: (3, 128, 128)\n",
      "Image 14 shape: torch.Size([3, 128, 128]), dtype: torch.float32\n",
      "Label 14: tensor([0, 0, 0, 0, 0, 0, 1, 0])\n",
      "Image shape is: (3, 128, 128)\n",
      "Image 15 shape: torch.Size([3, 128, 128]), dtype: torch.float32\n",
      "Label 15: tensor([0, 0, 0, 0, 0, 0, 1, 0])\n",
      "Image shape is: (3, 128, 128)\n",
      "Image 16 shape: torch.Size([3, 128, 128]), dtype: torch.float32\n",
      "Label 16: tensor([0, 0, 0, 0, 0, 0, 1, 0])\n",
      "Image shape is: (3, 128, 128)\n",
      "Image 17 shape: torch.Size([3, 128, 128]), dtype: torch.float32\n",
      "Label 17: tensor([0, 0, 0, 0, 0, 0, 1, 0])\n",
      "Image shape is: (3, 128, 128)\n",
      "Image 18 shape: torch.Size([3, 128, 128]), dtype: torch.float32\n",
      "Label 18: tensor([0, 0, 0, 0, 0, 0, 1, 0])\n",
      "Image shape is: (3, 128, 128)\n",
      "Image 19 shape: torch.Size([3, 128, 128]), dtype: torch.float32\n",
      "Label 19: tensor([0, 0, 0, 0, 0, 0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "#Test dataset\n",
    "for i in range(20):\n",
    "    img, label = dataset[i]\n",
    "    print(f\"Image {i} shape: {img.shape}, dtype: {img.dtype}\")\n",
    "    print(f\"Label {i}: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cff414d",
   "metadata": {},
   "source": [
    "Using ResNet18 as model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "31bfc05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the train dataset is 9245\n",
      "The size of the eval dataset is 2641\n",
      "The size of the test dataset is 1322\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load pretrained ResNet-18 model\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "\n",
    "# Modify the final fully connected layer and establish model parameters\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "num_classes = 8\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#Split dataset\n",
    "# Total size of the dataset\n",
    "total_size = len(dataset)\n",
    "\n",
    "# Calculate split sizes\n",
    "train_size = int(0.7 * total_size)\n",
    "eval_size = int(0.2 * total_size)\n",
    "test_size = total_size - train_size - eval_size  # Ensures full coverage\n",
    "\n",
    "# Random split\n",
    "train_dataset, eval_dataset, test_dataset = random_split(\n",
    "    dataset,\n",
    "    [train_size, eval_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(42))  # For reproducibility\n",
    "print(f\"The size of the train dataset is {len(train_dataset)}\")\n",
    "print(f\"The size of the eval dataset is {len(eval_dataset)}\")\n",
    "print(f\"The size of the test dataset is {len(test_dataset)}\")\n",
    "\n",
    "# Data loader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masketeers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
