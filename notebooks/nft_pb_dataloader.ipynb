{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63e0d346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import zarr\n",
    "from skimage.segmentation import relabel_sequential\n",
    "from scipy.ndimage import distance_transform_edt, map_coordinates\n",
    "from matplotlib import gridspec, ticker\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torch.nn as nn\n",
    "from dlmbl_unet import UNet\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.v2 as transforms_v2\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "from scipy.optimize import linear_sum_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61eaf3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions\n",
    "def load_data (zarr_path):\n",
    "    x_arrays = []\n",
    "    y_arrays = []\n",
    "    root = zarr.open (zarr_path)\n",
    "    for conditions in list (root.keys()):\n",
    "        images = root [conditions].keys()\n",
    "        for fov in images:\n",
    "            x = root[conditions][fov][\"x_cropped\"][:].astype (\"float32\")\n",
    "            y = root[conditions][fov][\"y_cropped\"][:].astype (\"int16\")\n",
    "            \n",
    "            for i in range (x.shape[0]):\n",
    "                x_slice = np.expand_dims (x[i, :, :], axis = 0)\n",
    "                y_slice = np.expand_dims (y [i, :, :], axis = 0)\n",
    "                # print (x_slice.shape, y_slice.shape)\n",
    "                if int (y_slice.max () )> 0:\n",
    "                    x_arrays.append (x_slice)\n",
    "                    y_arrays.append (y_slice)\n",
    "    x_array = np.concatenate (x_arrays)\n",
    "    y_array = np.concatenate (y_arrays)\n",
    "\n",
    "    return x_array, y_array\n",
    "\n",
    "\n",
    "def compute_sdt(labels: np.ndarray, scale: int = 5):\n",
    "    \"\"\"Function to compute a signed distance transform.\"\"\"\n",
    "    dims = len(labels.shape)\n",
    "    # Create a placeholder array of infinite distances\n",
    "    distances = np.ones(labels.shape, dtype=np.float32) * np.inf\n",
    "    for axis in range(dims):\n",
    "        # Here we compute the boundaries by shifting the labels and comparing to the original labels\n",
    "        # This can be visualized in 1D as:\n",
    "        # a a a b b c c c\n",
    "        #   a a a b b c c c\n",
    "        #   1 1 0 1 0 1 1\n",
    "        # Applying a half pixel shift makes the result more obvious:\n",
    "        # a a a b b c c c\n",
    "        #  1 1 0 1 0 1 1\n",
    "        bounds = (\n",
    "            labels[*[slice(None) if a != axis else slice(1, None) for a in range(dims)]]\n",
    "            == labels[\n",
    "                *[slice(None) if a != axis else slice(None, -1) for a in range(dims)]\n",
    "            ]\n",
    "        )\n",
    "        # pad to account for the lost pixel\n",
    "        bounds = np.pad(\n",
    "            bounds,\n",
    "            [(1, 1) if a == axis else (0, 0) for a in range(dims)],\n",
    "            mode=\"constant\",\n",
    "            constant_values=1,\n",
    "        )\n",
    "        # compute distances on the boundary mask\n",
    "        axis_distances = distance_transform_edt(bounds)\n",
    "\n",
    "        # compute the coordinates of each original pixel relative to the boundary mask and distance transform.\n",
    "        # Its just a half pixel shift in the axis we computed boundaries for.\n",
    "        coordinates = np.meshgrid(\n",
    "            *[\n",
    "                (\n",
    "                    range(axis_distances.shape[a])\n",
    "                    if a != axis\n",
    "                    else np.linspace(\n",
    "                        0.5, axis_distances.shape[a] - 1.5, labels.shape[a]\n",
    "                    )\n",
    "                )\n",
    "                for a in range(dims)\n",
    "            ],\n",
    "            indexing=\"ij\",\n",
    "        )\n",
    "        coordinates = np.stack(coordinates)\n",
    "\n",
    "        # Interpolate the distances to the original pixel coordinates\n",
    "        sampled = map_coordinates(\n",
    "            axis_distances,\n",
    "            coordinates=coordinates,\n",
    "            order=3,\n",
    "        )\n",
    "\n",
    "        # Update the distances with the minimum distance to a boundary in this axis\n",
    "        distances = np.minimum(distances, sampled)\n",
    "\n",
    "    # Normalize the distances to be between -1 and 1\n",
    "    distances = np.tanh(distances / scale)\n",
    "\n",
    "    # Invert the distances for pixels in the background\n",
    "    distances[labels == 0] *= -1\n",
    "    return distances\n",
    "\n",
    "def train(\n",
    "    model,\n",
    "    loader,\n",
    "    optimizer,\n",
    "    loss_function,\n",
    "    epoch,\n",
    "    log_interval=100,\n",
    "    log_image_interval=20,\n",
    "    tb_logger=None,\n",
    "    device=None,\n",
    "    early_stop=False,\n",
    "):\n",
    "    if device is None:\n",
    "        # You can pass in a device or we will default to using\n",
    "        # the gpu. Feel free to try training on the cpu to see\n",
    "        # what sort of performance difference there is\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device(\"cuda\")\n",
    "        else:\n",
    "            device = torch.device(\"cpu\")\n",
    "\n",
    "    # set the model to train mode\n",
    "    model.train()\n",
    "\n",
    "    # move model to device\n",
    "    model = model.to(device)\n",
    "\n",
    "    # iterate over the batches of this epoch\n",
    "    for batch_id, (x, y, z) in enumerate(loader):\n",
    " \n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        # zero the gradients for this iteration\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # apply model and calculate loss\n",
    "        prediction = model(x)\n",
    "        assert prediction.shape == y.shape, (prediction.shape, y.shape)\n",
    "        if y.dtype != prediction.dtype:\n",
    "            y = y.type(prediction.dtype)\n",
    "        loss = loss_function(prediction, y)\n",
    "\n",
    "        # backpropagate the loss and adjust the parameters\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # log to console\n",
    "        if batch_id % log_interval == 0:\n",
    "            print(\n",
    "                \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                    epoch,\n",
    "                    batch_id * len(x),\n",
    "                    len(loader.dataset),\n",
    "                    100.0 * batch_id / len(loader),\n",
    "                    loss.item(),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        # log to tensorboard\n",
    "        if tb_logger is not None:\n",
    "            step = epoch * len(loader) + batch_id\n",
    "            tb_logger.add_scalar(\n",
    "                tag=\"train_loss\", scalar_value=loss.item(), global_step=step\n",
    "            )\n",
    "            # check if we log images in this iteration\n",
    "            if step % log_image_interval == 0:\n",
    "                tb_logger.add_images(\n",
    "                    tag=\"input\", img_tensor=x.to(\"cpu\"), global_step=step\n",
    "                )\n",
    "                tb_logger.add_images(\n",
    "                    tag=\"target\", img_tensor=y.to(\"cpu\"), global_step=step\n",
    "                )\n",
    "                tb_logger.add_images(\n",
    "                    tag=\"prediction\",\n",
    "                    img_tensor=prediction.to(\"cpu\").detach(),\n",
    "                    global_step=step,\n",
    "                )\n",
    "\n",
    "        if early_stop and batch_id > 5:\n",
    "            print(\"Stopping test early!\")\n",
    "            break\n",
    "\n",
    "def launch_tensorboard(log_dir):\n",
    "    import socket\n",
    "\n",
    "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "        s.bind((\"\", 0))\n",
    "        port = s.getsockname()[1]\n",
    "\n",
    "    tensorboard_cmd = f\"tensorboard --logdir={log_dir} --port={port}\"\n",
    "    process = subprocess.Popen(tensorboard_cmd, shell=True)\n",
    "    print(\n",
    "        f\"TensorBoard started at http://localhost:{port}. \\n\"\n",
    "        \"If you are using VSCode remote session, forward the port using the PORTS tab next to TERMINAL.\"\n",
    "    )\n",
    "    return process\n",
    "\n",
    "def plot_two(img: np.ndarray, intermediate: np.ndarray, label: str):\n",
    "    \"\"\"\n",
    "    Helper function to plot an image and the auxiliary (intermediate)\n",
    "    representation of the target.\n",
    "    \"\"\"\n",
    "    if img.shape[0] == 2 and len(img.shape) == 3:\n",
    "        img = np.array([img[0], img[1], img[0] * 0]).transpose((1, 2, 0))\n",
    "    if intermediate.shape[0] == 4 and len(intermediate.shape) == 3:\n",
    "        intermediate = np.array(\n",
    "            [\n",
    "                (intermediate[0] + intermediate[2]) / 2,\n",
    "                (intermediate[1] + intermediate[3]) / 2,\n",
    "                intermediate.sum(axis=0) > 0,  # any affinity is 1\n",
    "            ]\n",
    "        ).transpose((1, 2, 0))\n",
    "    fig = plt.figure(constrained_layout=False, figsize=(10, 3))\n",
    "    spec = gridspec.GridSpec(ncols=2, nrows=1, figure=fig)\n",
    "    ax1 = fig.add_subplot(spec[0, 0])\n",
    "    ax1.set_xlabel(\"Image\", fontsize=20)\n",
    "    plt.imshow(img)\n",
    "    ax2 = fig.add_subplot(spec[0, 1])\n",
    "    ax2.set_xlabel(label, fontsize=20)\n",
    "    if len(intermediate.shape) == 2:\n",
    "        t = plt.imshow(intermediate, cmap=\"coolwarm\")\n",
    "        cbar = fig.colorbar(t, fraction=0.046, pad=0.04)\n",
    "        tick_locator = ticker.MaxNLocator(nbins=3)\n",
    "        cbar.locator = tick_locator\n",
    "        cbar.update_ticks()\n",
    "        _ = [ax.set_xticks([]) for ax in [ax1, ax2]]\n",
    "        _ = [ax.set_yticks([]) for ax in [ax1, ax2]]\n",
    "    elif len(intermediate.shape) == 3:\n",
    "        plt.imshow(intermediate)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_three(\n",
    "    img: np.ndarray,\n",
    "    intermediate: np.ndarray,\n",
    "    pred: np.ndarray,\n",
    "    label: str = \"Target\",\n",
    "    label_cmap=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Helper function to plot an image, the auxiliary (intermediate)\n",
    "    representation of the target and the model prediction.\n",
    "    \"\"\"\n",
    "    if img.shape[0] == 2 and len(img.shape) == 3:\n",
    "        img = np.array([img[0], img[1], img[0] * 0]).transpose((1, 2, 0))\n",
    "    if intermediate.shape[0] == 4 and len(intermediate.shape) == 3:\n",
    "        intermediate = np.array(\n",
    "            [\n",
    "                (intermediate[0] + intermediate[2]) / 2,\n",
    "                (intermediate[1] + intermediate[3]) / 2,\n",
    "                intermediate.sum(axis=0) > 0,  # any affinity is 1\n",
    "            ]\n",
    "        ).transpose((1, 2, 0))\n",
    "    if pred.shape[0] == 4 and len(pred.shape) == 3:\n",
    "        pred = np.array(\n",
    "            [(pred[0] + pred[2]) / 2, (pred[1] + pred[3]) / 2, pred.mean(axis=0)]\n",
    "        ).transpose((1, 2, 0))\n",
    "    fig = plt.figure(constrained_layout=False, figsize=(10, 3))\n",
    "    spec = gridspec.GridSpec(ncols=3, nrows=1, figure=fig)\n",
    "    ax1 = fig.add_subplot(spec[0, 0])\n",
    "    ax1.set_xlabel(\"Image\", fontsize=20)\n",
    "    plt.imshow(img)\n",
    "    ax2 = fig.add_subplot(spec[0, 1])\n",
    "    if label_cmap is not None:\n",
    "        ax2.set_xlabel(\"Labels\", fontsize=20)\n",
    "    else:\n",
    "        ax2.set_xlabel(label, fontsize=20)\n",
    "\n",
    "    if len(intermediate.shape) == 2:\n",
    "        if label_cmap is None:\n",
    "            plt.imshow(intermediate, cmap=\"coolwarm\")\n",
    "        else:\n",
    "            plt.imshow(intermediate, cmap=label_cmap, interpolation=\"none\")\n",
    "    else:\n",
    "        plt.imshow(intermediate)\n",
    "    ax3 = fig.add_subplot(spec[0, 2])\n",
    "    if label_cmap is not None:\n",
    "        ax3.set_xlabel(label, fontsize=20)\n",
    "    else:\n",
    "        ax3.set_xlabel(\"Prediction\", fontsize=20)\n",
    "\n",
    "    if len(pred.shape) == 2:\n",
    "        t = plt.imshow(pred, cmap=\"coolwarm\")\n",
    "        cbar = fig.colorbar(t, fraction=0.046, pad=0.04)\n",
    "        tick_locator = ticker.MaxNLocator(nbins=3)\n",
    "        cbar.locator = tick_locator\n",
    "        cbar.update_ticks()\n",
    "        _ = [ax.set_xticks([]) for ax in [ax1, ax2, ax3]]  # remove the xticks\n",
    "        _ = [ax.set_yticks([]) for ax in [ax1, ax2, ax3]]  # remove the yticks\n",
    "    else:\n",
    "        plt.imshow(pred)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_four(\n",
    "    img: np.ndarray,\n",
    "    intermediate: np.ndarray,\n",
    "    pred: np.ndarray,\n",
    "    seg: np.ndarray,\n",
    "    label: str = \"Target\",\n",
    "    cmap: str = \"nipy_spectral\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Helper function to plot an image, the auxiliary (intermediate)\n",
    "    representation of the target, the model prediction and the predicted segmentation mask.\n",
    "    \"\"\"\n",
    "\n",
    "    if img.shape[0] == 2 and len(img.shape) == 3:\n",
    "        img = np.array([img[0], img[1], img[0] * 0]).transpose((1, 2, 0))\n",
    "    if intermediate.shape[0] == 4 and len(intermediate.shape) == 3:\n",
    "        intermediate = np.array(\n",
    "            [\n",
    "                (intermediate[0] + intermediate[2]) / 2,\n",
    "                (intermediate[1] + intermediate[3]) / 2,\n",
    "                intermediate.sum(axis=0) > 0,  # any affinity is 1\n",
    "            ]\n",
    "        ).transpose((1, 2, 0))\n",
    "    if pred.shape[0] == 4 and len(pred.shape) == 3:\n",
    "        pred = np.array(\n",
    "            [(pred[0] + pred[2]) / 2, (pred[1] + pred[3]) / 2, pred.mean(axis=0)]\n",
    "        ).transpose((1, 2, 0))\n",
    "    fig = plt.figure(constrained_layout=False, figsize=(10, 3))\n",
    "    spec = gridspec.GridSpec(ncols=4, nrows=1, figure=fig)\n",
    "    ax1 = fig.add_subplot(spec[0, 0])\n",
    "    ax1.imshow(img)  # show the image\n",
    "    ax1.set_xlabel(\"Image\", fontsize=20)\n",
    "    ax2 = fig.add_subplot(spec[0, 1])\n",
    "    if len(intermediate.shape) == 2:\n",
    "        ax2.imshow(intermediate, cmap=\"coolwarm\")\n",
    "    else:\n",
    "        ax2.imshow(intermediate)\n",
    "    ax2.set_xlabel(label, fontsize=20)\n",
    "    ax3 = fig.add_subplot(spec[0, 2])\n",
    "    if len(pred.shape) == 2:\n",
    "        t = ax3.imshow(pred, cmap=\"coolwarm\")\n",
    "        tick_locator = ticker.MaxNLocator(nbins=3)\n",
    "        cbar = fig.colorbar(t, fraction=0.046, pad=0.04)\n",
    "        cbar.locator = tick_locator\n",
    "        cbar.update_ticks()\n",
    "    else:\n",
    "        ax3.imshow(pred)\n",
    "    ax3.set_xlabel(\"Pred.\", fontsize=20)\n",
    "    ax4 = fig.add_subplot(spec[0, 3])\n",
    "    ax4.imshow(seg, cmap=cmap, interpolation=\"none\")\n",
    "    ax4.set_xlabel(\"Seg.\", fontsize=20)\n",
    "    _ = [ax.set_xticks([]) for ax in [ax1, ax2, ax3, ax4]]  # remove the xticks\n",
    "    _ = [ax.set_yticks([]) for ax in [ax1, ax2, ax3, ax4]]  # remove the yticks\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def evaluate(gt_labels: np.ndarray, pred_labels: np.ndarray, th: float = 0.5):\n",
    "    \"\"\"Function to evaluate a segmentation.\"\"\"\n",
    "\n",
    "    pred_labels_rel, _, _ = relabel_sequential(pred_labels)\n",
    "    gt_labels_rel, _, _ = relabel_sequential(gt_labels)\n",
    "\n",
    "    overlay = np.array([pred_labels_rel.flatten(), gt_labels_rel.flatten()])\n",
    "\n",
    "    # get overlaying cells and the size of the overlap\n",
    "    overlay_labels, overlay_labels_counts = np.unique(\n",
    "        overlay, return_counts=True, axis=1\n",
    "    )\n",
    "    overlay_labels = np.transpose(overlay_labels)\n",
    "\n",
    "    # get gt cell ids and the size of the corresponding cell\n",
    "    gt_labels_list, gt_counts = np.unique(gt_labels_rel, return_counts=True)\n",
    "    gt_labels_count_dict = {}\n",
    "\n",
    "    for l, c in zip(gt_labels_list, gt_counts):\n",
    "        gt_labels_count_dict[l] = c\n",
    "\n",
    "    # get pred cell ids\n",
    "    pred_labels_list, pred_counts = np.unique(pred_labels_rel, return_counts=True)\n",
    "\n",
    "    pred_labels_count_dict = {}\n",
    "    for l, c in zip(pred_labels_list, pred_counts):\n",
    "        pred_labels_count_dict[l] = c\n",
    "\n",
    "    num_pred_labels = int(np.max(pred_labels_rel))\n",
    "    num_gt_labels = int(np.max(gt_labels_rel))\n",
    "    num_matches = min(num_gt_labels, num_pred_labels)\n",
    "\n",
    "    # create iou table\n",
    "    iouMat = np.zeros((num_gt_labels + 1, num_pred_labels + 1), dtype=np.float32)\n",
    "\n",
    "    for (u, v), c in zip(overlay_labels, overlay_labels_counts):\n",
    "        iou = c / (gt_labels_count_dict[v] + pred_labels_count_dict[u] - c)\n",
    "        iouMat[int(v), int(u)] = iou\n",
    "\n",
    "    # remove background\n",
    "    iouMat = iouMat[1:, 1:]\n",
    "\n",
    "    # use IoU threshold th\n",
    "    if num_matches > 0 and np.max(iouMat) > th:\n",
    "        costs = -(iouMat > th).astype(float) - iouMat / (2 * num_matches)\n",
    "        gt_ind, pred_ind = linear_sum_assignment(costs)\n",
    "        assert num_matches == len(gt_ind) == len(pred_ind)\n",
    "        match_ok = iouMat[gt_ind, pred_ind] > th\n",
    "        tp = np.count_nonzero(match_ok)\n",
    "    else:\n",
    "        tp = 0\n",
    "    fp = num_pred_labels - tp\n",
    "    fn = num_gt_labels - tp\n",
    "    precision = tp / max(1, tp + fp)\n",
    "    recall = tp / max(1, tp + fn)\n",
    "    accuracy = tp / (tp + fp + fn)\n",
    "\n",
    "    return precision, recall, accuracy\n",
    "\n",
    "class DiceCoefficient(nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    # the dice coefficient of two sets represented as vectors a, b ca be\n",
    "    # computed as (2 *|a b| / (a^2 + b^2))\n",
    "    def forward(self, prediction, target):\n",
    "        intersection = (prediction * target).sum()\n",
    "        union = (prediction * prediction).sum() + (target * target).sum()\n",
    "        return 2 * intersection / union.clamp(min=self.eps)\n",
    "class DiceLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    This layer will simply compute the dice coefficient and then negate\n",
    "    it with an optional offset.\n",
    "    We support an optional offset because it is common to have 0 as\n",
    "    the optimal loss. Since the optimal dice coefficient is 1, it is\n",
    "    convenient to get 1 - dice_coefficient as our loss.\n",
    "\n",
    "    You could leave off the offset and simply have -1 as your optimal loss.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, offset: float = 1):\n",
    "        super().__init__()\n",
    "        self.offset = torch.nn.Parameter(torch.tensor(offset), requires_grad=False)\n",
    "        self.dice_coefficient = DiceCoefficient()\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        coefficient = self.dice_coefficient(x, y)\n",
    "        return self.offset - coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "341cfe76",
   "metadata": {},
   "outputs": [],
   "source": [
    "zarr_path = \"/mnt/efs/aimbl_2025/student_data/S-DM/Data/zarr_storage/tangles_and_pbodies.zarr\"\n",
    "root = zarr.open (zarr_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb51073",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CropDataset(Dataset):\n",
    "    def __init__(self, zarr_path, transform = None, img_transform = None):\n",
    "        \n",
    "        \n",
    "        self.zarr_path = zarr_path\n",
    "\n",
    "        self.x, self.y = load_data(self.zarr_path)\n",
    "        self.transform = transform\n",
    "        self.img_transform = img_transform\n",
    "        \n",
    "       \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.x[idx]  \n",
    "        seg = self.y[idx] \n",
    "\n",
    "        img = torch.tensor(img).unsqueeze(0)\n",
    "        seg = torch.tensor(seg).unsqueeze(0)\n",
    "        sdt = torch.tensor (compute_sdt (seg))\n",
    "        \n",
    "        if self.transform:\n",
    "            seed = torch.seed()\n",
    "            torch.manual_seed(seed)\n",
    "            img = self.transform (img)\n",
    "            torch.manual_seed(seed)\n",
    "            seg = self.transform(seg)\n",
    "            torch.manual_seed(seed)\n",
    "            sdt = self.transform(sdt)\n",
    "            # img, sdt, seg = self.transform (img, sdt, seg)\n",
    "        \n",
    "        if self.img_transform:\n",
    "            img = self.img_transform(img)\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "        return torch.tensor(img, dtype=torch.float32), torch.tensor(sdt, dtype=torch.float32), seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebb893ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CropDataset (zarr_path=zarr_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22735088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3409\n"
     ]
    }
   ],
   "source": [
    "print (len (dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c7f5237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 256])\n",
      "<built-in method max of Tensor object at 0x704020228e30>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_673640/3981260206.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(img, dtype=torch.float32), torch.tensor(sdt, dtype=torch.float32), seg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7040201167d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = random.choice (range(0, len (dataset)))\n",
    "img = dataset [index][0].squeeze(0)\n",
    "print (img.shape)\n",
    "sdt = dataset[index][1].squeeze (0)\n",
    "print (sdt.max) # get the image and the distance transform\n",
    "# We use the <code style=\"color: black\">plot_two</code> function (imported in the first cell) to verify that our\n",
    "# dataset solution is correct. The output should show 2 images: the raw image and\n",
    "# the corresponding SDT.\n",
    "# plot_two(img, sdt,  label=\"SDT\")\n",
    "# sdt.shape\n",
    "\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(img, cmap = \"grey\")\n",
    "ax[1].imshow(sdt, cmap = \"seismic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fdcc2377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset contains 2728 images\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed (41)\n",
    "\n",
    "training, validation = random_split(dataset, lengths = (0.8, 0.2))\n",
    "print (f\"Training dataset contains {len (training)} images\")\n",
    "train_dataloader = DataLoader (training, shuffle=True, batch_size=16)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "model = UNet(\n",
    "    depth = 4,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    final_activation=nn.Tanh(),\n",
    "    num_fmaps=16\n",
    ")\n",
    "\n",
    "learning_rate = 1e-4\n",
    "loss = DiceLoss()\n",
    "optimizer = torch.optim.Adam (model.parameters(), lr = learning_rate)\n",
    "\n",
    "logger = SummaryWriter(\"runs/tangles_pbodies_segmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ab6e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_tensorboard(\"runs\")\n",
    "\n",
    "for epoch in range(1000):\n",
    "    train (model= model,\n",
    "           loader = train_dataloader,\n",
    "            optimizer = optimizer,\n",
    "            loss_function = loss, epoch = epoch, device=device, tb_logger=logger)\n",
    "    if epoch % 10 ==0:\n",
    "        torch.save(\n",
    "            {\n",
    "            \"unet\": model.state_dict(),\n",
    "            \"epoch\": epoch,\n",
    "                # \"losses\": losses,\n",
    "                },\n",
    "                f\"/mnt/efs/aimbl_2025/student_data/S-DM/Data/checkpoints/unet_{epoch}.pth\",)\n",
    "print (\"Training completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masketeers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
