{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aff06d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"DISPLAY\"] = ':1001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dbe02d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "viewer=napari.Viewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b1d5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_763347/3513194516.py:2: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  marker=io.imread('/mnt/efs/aimbl_2025/student_data/S-LS/merged/img_001_merged.tif')\n",
      "/tmp/ipykernel_763347/3513194516.py:3: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  annotation=io.imread('/mnt/efs/aimbl_2025/student_data/S-LS/binary_rings-gt-tiff/img_000_binary_gt_positive.tif')\n",
      "/tmp/ipykernel_763347/3513194516.py:4: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  ring=io.imread('/mnt/efs/aimbl_2025/student_data/S-LS/binary_rings-predicted-tiff/img_000_binary_positive.tif')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Labels layer 'annotation' at 0x717dce8b7d90>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: The value -1 is out of bounds for dtype uint32 that allow for range [0, 4294967295].\n",
      "You can convert the layer dtype in the right-click contextual menu of the layer list.\n"
     ]
    }
   ],
   "source": [
    "import imageio as io\n",
    "marker=io.imread('/mnt/efs/aimbl_2025/student_data/S-LS/merged/img_001_merged.tif')\n",
    "annotation=io.imread('/mnt/efs/aimbl_2025/student_data/S-LS/binary_rings-gt-tiff/img_000_binary_gt_positive.tif')\n",
    "ring=io.imread('/mnt/efs/aimbl_2025/student_data/S-LS/binary_rings-predicted-tiff/img_000_binary_positive.tif')\n",
    "# raw=io.imread('/mnt/efs/aimbl_2025/student_data/S-LS/raw_bacteria/img_001_bacteria.tif')\n",
    "\n",
    "\n",
    "viewer.add_image(raw, name=\"raw_image\")\n",
    "# viewer.add_image(marker, channel_axis=0, name='marker')\n",
    "# viewer.add_image(marker, name='marker')\n",
    "viewer.add_labels(ring, name='prediction')\n",
    "viewer.add_labels(annotation, name='annotation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "926baf14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2208, 2752)\n"
     ]
    }
   ],
   "source": [
    "print(marker.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75564f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d9a0402",
   "metadata": {},
   "source": [
    "Here’s a quick, bacteria-focused rundown of the metrics you mentioned—what they mean, how they’re computed, and when to use them. I’ll show tiny numeric examples so the intuition sticks.\n",
    "\n",
    "Pixel-level vs Instance-level (important!)\n",
    "\n",
    "Pixel-level: treat masks as binary images (bacteria vs background). Good for “overall foreground area” quality.\n",
    "\n",
    "Instance-level: treat each bacterium as its own object (needs instance labels). Good for “did we detect each bacterium, and how well?”\n",
    "\n",
    "You can (and often should) report one of each, because they answer different questions.\n",
    "\n",
    "Pixel-level metrics (binary masks)\n",
    "Precision (Positive Predictive Value)\n",
    "\n",
    "What it asks: Of all pixels I predicted as bacteria, how many were actually bacteria?\n",
    "\n",
    "Formula: precision = TP / (TP + FP)\n",
    "\n",
    "Example: You predicted 120k bacteria pixels; 100k are truly bacteria, 20k are background → precision = 100k / (100k+20k) = 0.833.\n",
    "Use when: You want to penalize “extra” smear/bleed of the mask into background.\n",
    "\n",
    "Recall (Sensitivity)\n",
    "\n",
    "What it asks: Of all true bacteria pixels, how many did I capture?\n",
    "\n",
    "Formula: recall = TP / (TP + FN)\n",
    "\n",
    "Example: There are 130k true bacteria pixels; you captured 100k → recall = 100k / (100k+30k) = 0.769.\n",
    "Use when: Missing bacteria area is costly.\n",
    "\n",
    "F1 score (same as Dice for binary segmentation)\n",
    "\n",
    "What it asks: Balanced overlap score combining precision and recall.\n",
    "\n",
    "Formula: F1 = 2·precision·recall / (precision + recall) = 2TP/(2TP+FP+FN)\n",
    "\n",
    "Example using above: F1 ≈ 2·0.833·0.769 / (0.833+0.769) ≈ 0.800.\n",
    "Use when: Single headline number for binary mask overlap—this is usually the most informative one-liner for “total bacteria” masks.\n",
    "\n",
    "Mean IoU (a.k.a. Jaccard)\n",
    "\n",
    "What it asks: How big is the intersection relative to the union?\n",
    "\n",
    "Formula: IoU = TP / (TP + FP + FN)\n",
    "\n",
    "Example with 100k TP, 20k FP, 30k FN: IoU = 100k/(100k+20k+30k)= 0.667.\n",
    "Use when: You want a stricter overlap score than Dice; common in papers/benchmarks.\n",
    "\n",
    "⚠️ Plain Accuracy can look great just because most pixels are background. Avoid it as a headline in segmentation.\n",
    "\n",
    "Instance-level metrics (objects)\n",
    "\n",
    "These require instance labels (0=background, 1..K for each bacterium). First you match predicted objects to GT objects (usually by IoU ≥ 0.5).\n",
    "\n",
    "Object Precision / Recall / F1\n",
    "\n",
    "What it asks: Did we detect the right objects (not just pixels)?\n",
    "\n",
    "TP: predicted object matched a GT object at IoU ≥ τ (e.g., 0.5)\n",
    "\n",
    "FP: predicted object with no match\n",
    "\n",
    "FN: GT object with no matched prediction\n",
    "\n",
    "Formulas: same as pixel precision/recall/F1 but counting objects instead of pixels.\n",
    "\n",
    "Example: In one image:\n",
    "\n",
    "GT bacteria = 50\n",
    "\n",
    "Predicted = 47\n",
    "\n",
    "Matches at IoU≥0.5 = 42\n",
    "→ TP=42, FP=5, FN=8 → precision=42/47=0.894, recall=42/50=0.840, F1≈0.866.\n",
    "Use when: You care about finding the right number of bacteria.\n",
    "\n",
    "Counting error\n",
    "\n",
    "What it asks: How far off is my count?\n",
    "\n",
    "Per image: |#pred − #gt|\n",
    "\n",
    "Dataset: mean absolute error (MAE) or signed error (bias)\n",
    "\n",
    "Example: GT=50, Pred=47 → |Δ|=3.\n",
    "Use when: You care about counts (e.g., density estimates).\n",
    "\n",
    "Mean IoU of matched instances\n",
    "\n",
    "What it asks: For the correctly detected bacteria, how good are the shapes?\n",
    "\n",
    "Compute IoU per matched pair; take the mean.\n",
    "\n",
    "Example: 42 matched bacteria have IoUs averaging 0.74.\n",
    "Use when: Shape/boundary quality matters (separate from detection).\n",
    "\n",
    "Note: This can stay flat even while detection improves (you saw this earlier).\n",
    "\n",
    "So…what’s “most accurate” for your comparison?\n",
    "\n",
    "You said: “comparing my mask with the StarDist mask of total bacteria” → sounds like binary foreground vs background comparison, not per-object analysis.\n",
    "\n",
    "If that’s right, the best single headline metric is Dice (F1).\n",
    "\n",
    "It balances missing area (FN) and extra area (FP), is robust to background imbalance, and is the standard for binary segmentation overlap.\n",
    "\n",
    "Also report IoU (it’s stricter and widely recognized).\n",
    "\n",
    "If you also care about detection/counts, add instance-level object F1 (at IoU≥0.5) and counting error.\n",
    "\n",
    "Quick recommendation set\n",
    "\n",
    "Primary: Dice (F1) and IoU on the binary masks.\n",
    "\n",
    "Optional (if you have instances): Object F1 @ IoU≥0.5 and counting error.\n",
    "\n",
    "Optional boundary quality: Boundary F1 (BF-score) if edge sharpness matters.\n",
    "\n",
    "Mini cheat-sheet\n",
    "\n",
    "Binary overlap quality: Dice/F1 (↑ better), IoU (↑ better).\n",
    "\n",
    "Too much foreground? Precision low.\n",
    "\n",
    "Missing bacteria area? Recall low.\n",
    "\n",
    "Too many/few bacteria? Look at object recall and counting error.\n",
    "\n",
    "Shapes on matched objects: Mean IoU of matches (or boundary F1).\n",
    "\n",
    "If you want, I can adapt your earlier evaluation code to output both binary Dice/IoU and instance-level object F1/counting error in one go, using the same folder structure you already set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e398abb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cellpose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
